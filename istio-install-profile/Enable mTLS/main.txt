we will deploy the sample application (Web Frontend and Customer service).

The web frontend will be deployed without an Envoy proxy sidecar, 
while the Customer service will have the sidecar injected.

With this setup, we will see how Istio can send both mTLS and plain text traffic and change the TLS mode to STRICT.
------------------------------------let  create gateway---------------------------------------------------------------------------------
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: gateway
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 80
        name: http
        protocol: HTTP
      hosts:
        - '*'
 ---------------------------USE CASE----------------------------------------------------------------------------------------       
Next, we will create the Web Frontend and the Customer service deployments and related Kubernetes services.

We will disable the automatic sidecar injection in the default namespace before deploying, 
so the proxy doesn’t get injected into the Web frontend deployment. 

Before we deploy the Customer service, we will enable the injection again.
--------------------------------------------------------------------------------------------------------------------------
$ kubectl label namespace default istio-injection-     <------disbled injection label of default ns
namespace/default labeled

With injection disabled, let’s deploy the web-frontend:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-frontend
  labels:
    app: web-frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: web-frontend
  template:
    metadata:
      labels:
        app: web-frontend
        version: v1
    spec:
      containers:
        - image: gcr.io/tetratelabs/web-frontend:1.0.0
          imagePullPolicy: Always
          name: web
          ports:
            - containerPort: 8080
          env:
            - name: CUSTOMER_SERVICE_URL
              value: 'http://customers.default.svc.cluster.local'
---
kind: Service
apiVersion: v1
metadata:
  name: web-frontend
  labels:
    app: web-frontend
spec:
  selector:
    app: web-frontend
  ports:
    - port: 80
      name: http
      targetPort: 8080
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: web-frontend
spec:
  hosts:
    - '*'
  gateways:
    - gateway
  http:
    - route:
        - destination:
            host: web-frontend.default.svc.cluster.local
            port:
              number: 80



 we should see one Pod with a single container running, indicated by the 1/1 in the READY column:

$ kubectl get po
NAME                           READY   STATUS    RESTARTS   AGE
web-frontend-659f65f49-cbhvl   1/1     Running   0          7m31s
------------------------------------------------------------------------------------------------------------------
Let’s enable the automatic injection:

$ kubectl label namespace default istio-injection=enabled
namespace/default labeled


And the deploy the v1 of the Customer service:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: customers-v1
  labels:
    app: customers
    version: v1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: customers
      version: v1
  template:
    metadata:
      labels:
        app: customers
        version: v1
    spec:
      containers:
        - image: gcr.io/tetratelabs/customers:1.0.0
          imagePullPolicy: Always
          name: svc
          ports:
            - containerPort: 3000
---
kind: Service
apiVersion: v1
metadata:
  name: customers
  labels:
    app: customers
spec:
  selector:
    app: customers
  ports:
    - port: 80
      name: http
      targetPort: 3000
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: customers
spec:
  hosts:
    - 'customers.default.svc.cluster.local'
  http:
    - route:
        - destination:
            host: customers.default.svc.cluster.local
            port:
              number: 80

----------------------------------------------------------------------------------------------------------------
We should have both applications deployed and running - the customers’ service will have two containers, 
and the web frontend service will have one:

$ kubectl get po
NAME                            READY   STATUS    RESTARTS   AGE
customers-v1-7857944975-qrqsz   2/2     Running   0          4m1s
web-frontend-659f65f49-cbhvl    1/1     Running   0          13m

-------------------------------------------------------------------------------------------------------------------
If we try and access the web page from the GATEWAY_URL, we will get the web page with the customer service’s response.

Accessing the GATEWAY_URL works because of the permissive mode, <----------------permissive mode(plaintext & mtls)
where plain text traffic gets sent to the services that don’t have the proxy. 

In this case, the ingress gateway sends plain text traffic to the Web frontend because there’s no proxy.

-----------kaili ----------------------------------------------------------------------------------------------------------------
ingress gateway-----------(send plaintext as no proxy in webfront)----->webfrontend(no envoy)------------------------->customer(envoy)

you will notice that Kiali detects calls made from the ingress gateway to web-frontend.

However, the calls made to the customers service are coming from unknown service. 

This is because there’s no proxy next to the web frontend. 

Therefore Istio doesn’t know who, where or what that service is.


ingressgateway------------>webfront

unknown------------------>customers
--------------------------------------------------------------------------------------------------------------------
Let’s update the customers VirtualService and attach the gateway to it. Attaching the gateway allows us 
to make calls directly to the customers service.

apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: customers
spec:
  hosts:
    - 'customers.default.svc.cluster.local'
  gateways:
    - gateway                  #gateway direct connect to customers service
  http:
    - route:
        - destination:
            host: customers.default.svc.cluster.local
            port:
              number: 80

We can now specify the Host header and we’ll be able to send the requests through the
ingress gateway (GATEWAY_URL) to the customers service:

$ curl -H "Host: customers.default.svc.cluster.local" http://$GATEWAY_URL;
[{"name":"Jewel Schaefer"},{"name":"Raleigh Larson"},{"name":"Eloise Senger"},{"name":"Moshe Zieme"},
{"name":"Filiberto Lubowitz"},{"name":"Ms.Kadin Kling"},{"name":"Jennyfer Bergstrom"},
{"name":"Candelario Rutherford"},{"name":"Kenyatta Flatley"},{"name":"Gianni Pouros"}]


-------------------------------------------------------------------------------------------------------------------------
To generate some traffic to both the Web frontend and Customers service through the ingress,
open the two terminal windows and run one command in each:


// Terminal 1 
$ while true; do curl -H "Host: customers.default.svc.cluster.local" http://$GATEWAY_URL; done
...
// Terminal 2
$ while true; do curl http://$GATEWAY_URL; done


now
ingressgateway----------mtls------->customers
ingressgateway----------plaintext------->webfront

------------------------------------------------------------------------------------------------------------------------------
Let’s see what happens if we enable mTLS in STRICT mode.

We expect the calls from the frontend to the customer service to start failing because 
there’s no proxy injected to do the mTLS communication.

On the other hand, the calls from the ingress gateway to the customer service will continue working.

ingressgateway----------mtls------->customers             <---------working
frontend(no envoy)--------------------------->customers(envoy)             <---------failing, as STRICT mode mtls (
                                                                      customers side closed con as want mtls but frontend can not)


apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication   # svc to svc communication
metadata:
  name: default
  namespace: default
spec:
  mtls:
    mode: STRICT



If we still have the request loop running, we will see the ECONNRESET error message from the web frontend.
This error indicates that the customers side closed the connection.
In our case, it was because it was expecting an mTLS connection.

On the other hand, the requests we’re making directly to the customers service continue to work 
because the customer service has an Envoy proxy running next to it and can do mutual TLS.


---------------------------------------------------------------------------------------------------------------------------
If we delete the PeerAuthentication resource deployed earlier (kubectl delete peerauthentication default),
Istio returns to its default (PERMISSIVE mode), and the errors will disappear.
------------------------------------------------------------------------------------------------------------------
