----------------------------INSTALL MULTI PRIMARY CLUSTERS-----------------------------------------------------------
install the Istio control plane on both cluster1 and cluster2, making each a primary cluster. 

Both clusters reside on the network1 network, meaning there is direct connectivity between the pods in both clusters.

In this configuration, each control plane observes the API Servers in both clusters for endpoints.

Service workloads communicate directly (pod-to-pod) across cluster boundaries.
---------------------------------cluster1.yaml--Configure cluster1 as a primary-----------------------------------
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
spec:
  values:
    global:
      meshID: mesh1
      multiCluster:
        clusterName: cluster1
      network: network1

$ istioctl install --context="cluster1" -f cluster1.yaml
---------------cluster2.yaml--Configure cluster2 as a primary------------------------------------------------------
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
spec:
  values:
    global:
      meshID: mesh1
      multiCluster:
        clusterName: cluster2
      network: network1

$ istioctl install --context="cluster2" -f cluster2.yaml
--------------------------------------Enable Endpoint Discovery------------------------------------------------------------
Install a remote secret in cluster2 that provides access to cluster1’s API server.

$ istioctl x create-remote-secret \
    --context="cluster1" \
    --name=cluster1 | \
    kubectl apply -f - --context="cluster2"

Install a remote secret in cluster1 that provides access to cluster2’s API server.

$ istioctl x create-remote-secret \
    --context="cluster2" \
    --name=cluster2 | \
    kubectl apply -f - --context="cluster1"

Congratulations! You successfully installed an Istio mesh across multiple primary clusters!
----------------we will deploy the HelloWorld application V1 to cluster1 and V2 to cluster2.-----------------------------

We will also deploy the Sleep container to both clusters. We will use these pods as the source of requests 
to the HelloWorld service, simulating in-mesh traffic.

Finally, after generating traffic, we will observe which cluster received the requests.

------------------Deploy the HelloWorld Service---------------------------------------------------------------------
In order to make the HelloWorld service callable from any cluster, the DNS lookup must succeed in each cluster.

We will address this by deploying the HelloWorld Service to each cluster in the mesh.

To begin, create the sample namespace in each cluster:

$ kubectl create --context="cluster1" namespace sample
$ kubectl create --context="cluster2" namespace sample

Enable automatic sidecar injection for the sample namespace:

$ kubectl label --context="cluster1" namespace sample \
    istio-injection=enabled
$ kubectl label --context="cluster2" namespace sample \
    istio-injection=enabled
-------------------------------helloworld.yaml---------------------------------------------------------------------
Create the HelloWorld service in both clusters:


apiVersion: v1
kind: Service
metadata:
  name: helloworld
  labels:
    app: helloworld
    service: helloworld
spec:
  ports:
  - port: 5000
    name: http
  selector:
    app: helloworld
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: helloworld-v1
  labels:
    app: helloworld
    version: v1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: helloworld
      version: v1
  template:
    metadata:
      labels:
        app: helloworld
        version: v1
    spec:
      containers:
      - name: helloworld
        image: docker.io/istio/examples-helloworld-v1
        resources:
          requests:
            cpu: "100m"
        imagePullPolicy: IfNotPresent #Always
        ports:
        - containerPort: 5000
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: helloworld-v2
  labels:
    app: helloworld
    version: v2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: helloworld
      version: v2
  template:
    metadata:
      labels:
        app: helloworld
        version: v2
    spec:
      containers:
      - name: helloworld
        image: docker.io/istio/examples-helloworld-v2
        resources:
          requests:
            cpu: "100m"
        imagePullPolicy: IfNotPresent #Always
        ports:
        - containerPort: 5000


Create the HelloWorld service in both clusters:

$ kubectl apply --context="cluster1" \
    -f helloworld.yaml \
    -l service=helloworld -n sample
$ kubectl apply --context="cluster2" \
    -f helloworld.yaml \
    -l service=helloworld -n sample        

-------------------------------Deploy HelloWorld V1-----------------------------------------------------------------
Deploy the helloworld-v1 application to cluster1:

$ kubectl apply --context="cluster1" \
    -f helloworld.yaml \
    -l version=v1 -n sample

Confirm the helloworld-v1 pod status:    

$ kubectl get pod --context="cluster1" -n sample -l app=helloworld
NAME                            READY     STATUS    RESTARTS   AGE
helloworld-v1-86f77cd7bd-cpxhv  2/2       Running   0          40s

Wait until the status of helloworld-v1 is Running.

-------------------------------------Deploy HelloWorld V2--------------------------------------------------------------------
Deploy the helloworld-v2 application to cluster2:

$ kubectl apply --context="cluster2" \
    -f helloworld.yaml \
    -l version=v2 -n sample

Confirm the status the helloworld-v2 pod status:

$ kubectl get pod --context="cluster2" -n sample -l app=helloworld
NAME                            READY     STATUS    RESTARTS   AGE
helloworld-v2-758dd55874-6x4t8  2/2       Running   0          40s

Wait until the status of helloworld-v2 is Running.

---------------------------------------Deploy Sleep-------------------------------------------------------------------
Deploy the Sleep application to both clusters:

##################################################################################################
# Sleep service
##################################################################################################
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sleep
---
apiVersion: v1
kind: Service
metadata:
  name: sleep
  labels:
    app: sleep
    service: sleep
spec:
  ports:
  - port: 80
    name: http
  selector:
    app: sleep
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sleep
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sleep
  template:
    metadata:
      labels:
        app: sleep
    spec:
      terminationGracePeriodSeconds: 0
      serviceAccountName: sleep
      containers:
      - name: sleep
        image: curlimages/curl
        command: ["/bin/sleep", "infinity"]
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - mountPath: /etc/sleep/tls
          name: secret-volume
      volumes:
      - name: secret-volume
        secret:
          secretName: sleep-secret
          optional: true
---





$ kubectl apply --context="cluster1" \
    -f sleep.yaml -n sample
$ kubectl apply --context="cluster2" \
    -f sleep.yaml -n sample

Confirm the status Sleep pod on cluster1:

$ kubectl get pod --context="cluster1" -n sample -l app=sleep
NAME                             READY   STATUS    RESTARTS   AGE
sleep-754684654f-n6bzf           2/2     Running   0          5s

Wait until the status of the Sleep pod is Running.

Confirm the status of the Sleep pod on cluster2:

$ kubectl get pod --context="cluster2" -n sample -l app=sleep
NAME                             READY   STATUS    RESTARTS   AGE
sleep-754684654f-dzl9j           2/2     Running   0          5s

Wait until the status of the Sleep pod is Running.
--------------------------------------Verifying Cross-Cluster Traffic----------------------------------------------
To verify that cross-cluster load balancing works as expected, call the HelloWorld service several times 
using the Sleep pod.

To ensure load balancing is working properly, call the HelloWorld service from all clusters in your deployment.

Send one request from the Sleep pod on cluster1 to the HelloWorld service:
$ kubectl exec --context="cluster1" -n sample -c sleep \
    "$(kubectl get pod --context="cluster1" -n sample -l \
    app=sleep -o jsonpath='{.items[0].metadata.name}')" \
    -- curl -sS helloworld.sample:5000/hello

Repeat this request several times and verify that the HelloWorld version should toggle between v1 and v2:

Hello version: v2, instance: helloworld-v2-758dd55874-6x4t8
Hello version: v1, instance: helloworld-v1-86f77cd7bd-cpxhv
...


Now repeat this process from the Sleep pod on cluster2:

$ kubectl exec --context="${CTX_CLUSTER2}" -n sample -c sleep \
    "$(kubectl get pod --context="${CTX_CLUSTER2}" -n sample -l \
    app=sleep -o jsonpath='{.items[0].metadata.name}')" \
    -- curl -sS helloworld.sample:5000/hello

Repeat this request several times and verify that the HelloWorld version should toggle between v1 and v2:

Hello version: v2, instance: helloworld-v2-758dd55874-6x4t8
Hello version: v1, instance: helloworld-v1-86f77cd7bd-cpxhv
...

Congratulations! You successfully installed and verified Istio on multiple clusters!
--------------------------------------------------------------------------------------------------------------
---
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: http-ingress-gateway
  namespace: sample
spec:
  # The selector matches the ingress gateway pod labels.
  # If you installed Istio using Helm following the standard documentation, this would be "istio=ingress"
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 8080
      name: http
      protocol: HTTP
    hosts:
      - "som.trycloud.co.in"   # domain name of external website
      - "sam.trycloud.co.in"
---    
kind: VirtualService
apiVersion: networking.istio.io/v1alpha3
metadata:
  name: helloworld-vs1
  namespace: sample
spec:
  hosts:
    - "som.trycloud.co.in"     # which incoming hosts are we applying proxy rules to. so copy the value of gateway host always
    #- fleetman-webapp.default.svc.cluster.local
  gateways:
    - http-ingress-gateway
  http:
    - route:
        - destination:
            host: helloworld.sample.svc.cluster.local
            subset: v1
          weight: 50
---
kind: VirtualService
apiVersion: networking.istio.io/v1alpha3
metadata:
  name: helloworld-vs2
  namespace: sample
spec:
  hosts:
    - "sam.trycloud.co.in"     # which incoming hosts are we applying proxy rules to. so copy the value of gateway host always
    #- fleetman-webapp.default.svc.cluster.local
  gateways:
    - http-ingress-gateway
  http:
    - route:
        - destination:
            host: helloworld.sample.svc.cluster.local
            subset: v2
          weight: 50
       
---
kind: DestinationRule
apiVersion: networking.istio.io/v1alpha3
metadata:
  name: helloworld-ds1
  namespace: sample
spec:
  host: helloworld.sample.svc.cluster.local
  trafficPolicy:
    loadBalancer:
      simple: ROUND_ROBIN
  subsets:
    - labels:
        version: v1
      name: v1
    - labels:
        version: v2
      name: v2
   
    

